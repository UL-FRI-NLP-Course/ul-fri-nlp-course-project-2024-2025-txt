# Natural language processing course: Analysis and comparison of translation errors and biases in LLMs

1. ABOUT:<br>
The purpose of this project is to analyze and compare translation errors and biases found in large language models(LLMs). We will evaluate how different models handle translations and look for common errors such as mistranslations, omissions and cultural misinterpretations. In addition we will also explore the bias that could emerge in translation, focus being political bias. By systematically comparing multiple LLMs, we aim to assess translation quality using both automated metrics and human evaluations. The project aims to help improve fairness and accuracy in AI-driven translation systems.

3. TEAM:<br>
   Tjaša Nadoh<br>
   Urška Roblek

4. REFERENCES
   
   [Roberto Navigli, Simone Conia, and Björn Ross. 2023. Biases in Large Language Models: Origins, Inventory, and Discussion. J. Data and Information Quality 15, 2, Article 10 (June
   2023)](https://doi.org/10.1145/3597307)<br>
   [Barclay, P. J., & Sami, A. (2024). Investigating Markers and Drivers of Gender Bias in Machine Translations. arXiv.Org, abs/2403.11896] (https://doi.org/10.48550/arxiv.2403.11896)
